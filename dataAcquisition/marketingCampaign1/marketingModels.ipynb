{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['campaign_item_id', 'no_of_days', 'time', 'ext_service_id',\n",
       "       'ext_service_name', 'creative_id', 'creative_width', 'creative_height',\n",
       "       'search_tags', 'template_id', 'landing_page', 'advertiser_id',\n",
       "       'advertiser_name', 'network_id', 'approved_budget',\n",
       "       'advertiser_currency', 'channel_id', 'channel_name', 'max_bid_cpm',\n",
       "       'network_margin', 'campaign_budget_usd', 'impressions', 'clicks',\n",
       "       'stats_currency', 'currency_code', 'exchange_rate', 'media_cost_usd',\n",
       "       'position_in_content', 'unique_reach', 'total_reach', 'search_tag_cat',\n",
       "       'cmi_currency_code', 'timezone', 'weekday_cat', 'keywords'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = pd.read_csv('./campaign1.csv')\n",
    "db.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 72612 entries, 0 to 72611\n",
      "Data columns (total 35 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   campaign_item_id     72612 non-null  int64  \n",
      " 1   no_of_days           72612 non-null  int64  \n",
      " 2   time                 72612 non-null  object \n",
      " 3   ext_service_id       72612 non-null  int64  \n",
      " 4   ext_service_name     72612 non-null  object \n",
      " 5   creative_id          72612 non-null  int64  \n",
      " 6   creative_width       69200 non-null  float64\n",
      " 7   creative_height      69200 non-null  float64\n",
      " 8   search_tags          72612 non-null  object \n",
      " 9   template_id          69200 non-null  float64\n",
      " 10  landing_page         72612 non-null  object \n",
      " 11  advertiser_id        72612 non-null  int64  \n",
      " 12  advertiser_name      72612 non-null  object \n",
      " 13  network_id           72612 non-null  int64  \n",
      " 14  approved_budget      72206 non-null  float64\n",
      " 15  advertiser_currency  72612 non-null  object \n",
      " 16  channel_id           72612 non-null  int64  \n",
      " 17  channel_name         72612 non-null  object \n",
      " 18  max_bid_cpm          7406 non-null   float64\n",
      " 19  network_margin       72612 non-null  float64\n",
      " 20  campaign_budget_usd  72612 non-null  float64\n",
      " 21  impressions          72612 non-null  int64  \n",
      " 22  clicks               72612 non-null  int64  \n",
      " 23  stats_currency       72612 non-null  object \n",
      " 24  currency_code        72612 non-null  object \n",
      " 25  exchange_rate        72612 non-null  int64  \n",
      " 26  media_cost_usd       72612 non-null  float64\n",
      " 27  position_in_content  0 non-null      float64\n",
      " 28  unique_reach         0 non-null      float64\n",
      " 29  total_reach          0 non-null      float64\n",
      " 30  search_tag_cat       72612 non-null  object \n",
      " 31  cmi_currency_code    72612 non-null  object \n",
      " 32  timezone             72612 non-null  object \n",
      " 33  weekday_cat          72612 non-null  object \n",
      " 34  keywords             72612 non-null  object \n",
      "dtypes: float64(11), int64(10), object(14)\n",
      "memory usage: 19.4+ MB\n"
     ]
    }
   ],
   "source": [
    "db.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_of_days</th>\n",
       "      <th>time</th>\n",
       "      <th>ext_service_name</th>\n",
       "      <th>creative_width</th>\n",
       "      <th>creative_height</th>\n",
       "      <th>approved_budget</th>\n",
       "      <th>advertiser_currency</th>\n",
       "      <th>campaign_budget_usd</th>\n",
       "      <th>impressions</th>\n",
       "      <th>clicks</th>\n",
       "      <th>currency_code</th>\n",
       "      <th>media_cost_usd</th>\n",
       "      <th>weekday_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>2022-05-01</td>\n",
       "      <td>Facebook Ads</td>\n",
       "      <td>300.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>SGD</td>\n",
       "      <td>652.173913</td>\n",
       "      <td>837</td>\n",
       "      <td>8</td>\n",
       "      <td>SGD</td>\n",
       "      <td>14.058514</td>\n",
       "      <td>week_end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>2022-05-02</td>\n",
       "      <td>DV360</td>\n",
       "      <td>300.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>SGD</td>\n",
       "      <td>652.173913</td>\n",
       "      <td>2634</td>\n",
       "      <td>44</td>\n",
       "      <td>SGD</td>\n",
       "      <td>99.633496</td>\n",
       "      <td>week_day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>2022-05-03</td>\n",
       "      <td>Facebook Ads</td>\n",
       "      <td>300.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>SGD</td>\n",
       "      <td>652.173913</td>\n",
       "      <td>2135</td>\n",
       "      <td>32</td>\n",
       "      <td>SGD</td>\n",
       "      <td>109.419677</td>\n",
       "      <td>week_day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>2022-05-04</td>\n",
       "      <td>Facebook Ads</td>\n",
       "      <td>300.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>SGD</td>\n",
       "      <td>652.173913</td>\n",
       "      <td>2327</td>\n",
       "      <td>48</td>\n",
       "      <td>SGD</td>\n",
       "      <td>115.209499</td>\n",
       "      <td>week_day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>2022-05-05</td>\n",
       "      <td>Google Ads</td>\n",
       "      <td>300.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>SGD</td>\n",
       "      <td>652.173913</td>\n",
       "      <td>1538</td>\n",
       "      <td>20</td>\n",
       "      <td>SGD</td>\n",
       "      <td>66.990104</td>\n",
       "      <td>week_day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72607</th>\n",
       "      <td>11</td>\n",
       "      <td>2022-11-28</td>\n",
       "      <td>Google Ads</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>442054.0</td>\n",
       "      <td>INR</td>\n",
       "      <td>306.635594</td>\n",
       "      <td>1059</td>\n",
       "      <td>56</td>\n",
       "      <td>INR</td>\n",
       "      <td>4.858090</td>\n",
       "      <td>week_day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72608</th>\n",
       "      <td>12</td>\n",
       "      <td>2022-11-29</td>\n",
       "      <td>Facebook Ads</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>442054.0</td>\n",
       "      <td>INR</td>\n",
       "      <td>306.635594</td>\n",
       "      <td>865</td>\n",
       "      <td>41</td>\n",
       "      <td>INR</td>\n",
       "      <td>3.536262</td>\n",
       "      <td>week_day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72609</th>\n",
       "      <td>13</td>\n",
       "      <td>2022-11-30</td>\n",
       "      <td>Facebook Ads</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>442054.0</td>\n",
       "      <td>INR</td>\n",
       "      <td>306.635594</td>\n",
       "      <td>646</td>\n",
       "      <td>21</td>\n",
       "      <td>INR</td>\n",
       "      <td>1.947816</td>\n",
       "      <td>week_day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72610</th>\n",
       "      <td>14</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>Google Ads</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>442054.0</td>\n",
       "      <td>INR</td>\n",
       "      <td>306.635594</td>\n",
       "      <td>658</td>\n",
       "      <td>20</td>\n",
       "      <td>INR</td>\n",
       "      <td>1.711467</td>\n",
       "      <td>week_day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72611</th>\n",
       "      <td>15</td>\n",
       "      <td>2022-12-02</td>\n",
       "      <td>DV360</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>442054.0</td>\n",
       "      <td>INR</td>\n",
       "      <td>306.635594</td>\n",
       "      <td>600</td>\n",
       "      <td>14</td>\n",
       "      <td>INR</td>\n",
       "      <td>0.990870</td>\n",
       "      <td>week_day</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72612 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       no_of_days        time ext_service_name  creative_width  \\\n",
       "0               7  2022-05-01     Facebook Ads           300.0   \n",
       "1               8  2022-05-02            DV360           300.0   \n",
       "2               9  2022-05-03     Facebook Ads           300.0   \n",
       "3              10  2022-05-04     Facebook Ads           300.0   \n",
       "4              11  2022-05-05       Google Ads           300.0   \n",
       "...           ...         ...              ...             ...   \n",
       "72607          11  2022-11-28       Google Ads             NaN   \n",
       "72608          12  2022-11-29     Facebook Ads             NaN   \n",
       "72609          13  2022-11-30     Facebook Ads             NaN   \n",
       "72610          14  2022-12-01       Google Ads             NaN   \n",
       "72611          15  2022-12-02            DV360             NaN   \n",
       "\n",
       "       creative_height  approved_budget advertiser_currency  \\\n",
       "0                250.0            400.0                 SGD   \n",
       "1                250.0            400.0                 SGD   \n",
       "2                250.0            400.0                 SGD   \n",
       "3                250.0            400.0                 SGD   \n",
       "4                250.0            400.0                 SGD   \n",
       "...                ...              ...                 ...   \n",
       "72607              NaN         442054.0                 INR   \n",
       "72608              NaN         442054.0                 INR   \n",
       "72609              NaN         442054.0                 INR   \n",
       "72610              NaN         442054.0                 INR   \n",
       "72611              NaN         442054.0                 INR   \n",
       "\n",
       "       campaign_budget_usd  impressions  clicks currency_code  media_cost_usd  \\\n",
       "0               652.173913          837       8           SGD       14.058514   \n",
       "1               652.173913         2634      44           SGD       99.633496   \n",
       "2               652.173913         2135      32           SGD      109.419677   \n",
       "3               652.173913         2327      48           SGD      115.209499   \n",
       "4               652.173913         1538      20           SGD       66.990104   \n",
       "...                    ...          ...     ...           ...             ...   \n",
       "72607           306.635594         1059      56           INR        4.858090   \n",
       "72608           306.635594          865      41           INR        3.536262   \n",
       "72609           306.635594          646      21           INR        1.947816   \n",
       "72610           306.635594          658      20           INR        1.711467   \n",
       "72611           306.635594          600      14           INR        0.990870   \n",
       "\n",
       "      weekday_cat  \n",
       "0        week_end  \n",
       "1        week_day  \n",
       "2        week_day  \n",
       "3        week_day  \n",
       "4        week_day  \n",
       "...           ...  \n",
       "72607    week_day  \n",
       "72608    week_day  \n",
       "72609    week_day  \n",
       "72610    week_day  \n",
       "72611    week_day  \n",
       "\n",
       "[72612 rows x 13 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.drop(['campaign_item_id', \n",
    "         'ext_service_id', \n",
    "         'creative_id',\n",
    "         'advertiser_id',\n",
    "         'channel_id', \n",
    "         'channel_name', \n",
    "         'timezone', \n",
    "         'search_tags', \n",
    "         'template_id', \n",
    "         'network_margin', \n",
    "         'exchange_rate', \n",
    "         'network_id', \n",
    "         'landing_page',\n",
    "         'cmi_currency_code',\n",
    "         'advertiser_name', \n",
    "         'keywords',\n",
    "         'search_tag_cat',\n",
    "         'stats_currency',\n",
    "         'position_in_content',\n",
    "         'total_reach',\n",
    "         'max_bid_cpm',\n",
    "         'unique_reach' \n",
    "         ], axis=1, inplace=True)\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 72612 entries, 0 to 72611\n",
      "Data columns (total 13 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   no_of_days           72612 non-null  int64  \n",
      " 1   time                 72612 non-null  object \n",
      " 2   ext_service_name     72612 non-null  object \n",
      " 3   creative_width       69200 non-null  float64\n",
      " 4   creative_height      69200 non-null  float64\n",
      " 5   approved_budget      72206 non-null  float64\n",
      " 6   advertiser_currency  72612 non-null  object \n",
      " 7   campaign_budget_usd  72612 non-null  float64\n",
      " 8   impressions          72612 non-null  int64  \n",
      " 9   clicks               72612 non-null  int64  \n",
      " 10  currency_code        72612 non-null  object \n",
      " 11  media_cost_usd       72612 non-null  float64\n",
      " 12  weekday_cat          72612 non-null  object \n",
      "dtypes: float64(5), int64(3), object(5)\n",
      "memory usage: 7.2+ MB\n"
     ]
    }
   ],
   "source": [
    "db.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 68880 entries, 0 to 69199\n",
      "Data columns (total 22 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   no_of_days                     68880 non-null  int64  \n",
      " 1   creative_width                 68880 non-null  float64\n",
      " 2   creative_height                68880 non-null  float64\n",
      " 3   approved_budget                68880 non-null  float64\n",
      " 4   campaign_budget_usd            68880 non-null  float64\n",
      " 5   impressions                    68880 non-null  int64  \n",
      " 6   clicks                         68880 non-null  int64  \n",
      " 7   media_cost_usd                 68880 non-null  float64\n",
      " 8   year                           68880 non-null  int32  \n",
      " 9   month                          68880 non-null  int32  \n",
      " 10  day                            68880 non-null  int32  \n",
      " 11  weekeEnd                       68880 non-null  bool   \n",
      " 12  ext_service_name_Facebook Ads  68880 non-null  bool   \n",
      " 13  ext_service_name_Google Ads    68880 non-null  bool   \n",
      " 14  currency_code_EGP              68880 non-null  bool   \n",
      " 15  currency_code_INR              68880 non-null  bool   \n",
      " 16  currency_code_SGD              68880 non-null  bool   \n",
      " 17  currency_code_USD              68880 non-null  bool   \n",
      " 18  advertiser_currency_EGP        68880 non-null  bool   \n",
      " 19  advertiser_currency_INR        68880 non-null  bool   \n",
      " 20  advertiser_currency_SGD        68880 non-null  bool   \n",
      " 21  advertiser_currency_USD        68880 non-null  bool   \n",
      "dtypes: bool(11), float64(5), int32(3), int64(3)\n",
      "memory usage: 6.2 MB\n"
     ]
    }
   ],
   "source": [
    "# Convert time columns to datetime\n",
    "db['time'] = pd.to_datetime(db['time'], format='%Y-%m-%d')\n",
    "db['year'] = db['time'].dt.year\n",
    "db['month'] = db['time'].dt.month\n",
    "db['day'] = db['time'].dt.day\n",
    "db.drop('time', axis=1, inplace=True)\n",
    "db.dropna(inplace=True)\n",
    "\n",
    "db_dummies = pd.get_dummies(db, columns=['weekday_cat', 'ext_service_name', 'currency_code', 'advertiser_currency'], drop_first=True)\n",
    "db_dummies.rename(columns={'weekday_cat_week_day': 'weekDay', 'weekday_cat_week_end': 'weekeEnd'}, inplace=True)\n",
    "db_dummies.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copying the databases\n",
    "df_budget = db_dummies['campaign_budget_usd']\n",
    "df_impression = db_dummies['impressions']\n",
    "df_clicks = db_dummies['clicks']\n",
    "df_media_cost_usd = db_dummies['media_cost_usd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split\n",
    "X_budget = db_dummies.copy().drop(['campaign_budget_usd'], axis=1)\n",
    "X_impression = db_dummies.copy().drop(['impressions'], axis=1)\n",
    "X_clicks = db_dummies.copy().drop(['clicks'], axis=1)\n",
    "X_media_cost_usd = db_dummies.copy().drop(['media_cost_usd'], axis=1)\n",
    "\n",
    "X_train_budget, X_test_budget, y_train_budget, y_test_budget = train_test_split(X_budget, df_budget, test_size=0.2, random_state=42)\n",
    "X_train_impression, X_test_impression, y_train_impression, y_test_impression = train_test_split(X_impression, df_impression, test_size=0.2, random_state=42)\n",
    "X_train_clicks, X_test_clicks, y_train_clicks, y_test_clicks = train_test_split(X_clicks, df_clicks, test_size=0.2, random_state=42)\n",
    "X_train_media_cost_usd, X_test_media_cost_usd, y_train_media_cost_usd, y_test_media_cost_usd = train_test_split(X_media_cost_usd, df_media_cost_usd, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_budget\n",
    "X_test = X_test_budget\n",
    "y_train = y_train_budget\n",
    "y_test = y_test_budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest MSE: 34577.87175471353\n",
      "Random Forest R^2: 0.90084835719238\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "print(f'Random Forest MSE: {mse_rf}')\n",
    "\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "print(f'Random Forest R^2: {r2_rf}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/santi/Desktop/Proyecto/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 618us/step - loss: 36399764.0000\n",
      "Epoch 2/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 602us/step - loss: 341948.7188\n",
      "Epoch 3/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 661us/step - loss: 11354824.0000\n",
      "Epoch 4/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616us/step - loss: 1143314.7500\n",
      "Epoch 5/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 605us/step - loss: 5668776.0000\n",
      "Epoch 6/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 603us/step - loss: 6596005.0000\n",
      "Epoch 7/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 613us/step - loss: 2050152.5000\n",
      "Epoch 8/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step - loss: 232454.9375\n",
      "Epoch 9/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 608us/step - loss: 458050.1562\n",
      "Epoch 10/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616us/step - loss: 1278438.7500\n",
      "Epoch 11/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 602us/step - loss: 225779.2969\n",
      "Epoch 12/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 601us/step - loss: 1806243.6250\n",
      "Epoch 13/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 669us/step - loss: 1528727.3750\n",
      "Epoch 14/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 607us/step - loss: 1109181.7500\n",
      "Epoch 15/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - loss: 229668.5938\n",
      "Epoch 16/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615us/step - loss: 2374292.0000\n",
      "Epoch 17/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620us/step - loss: 214332.2188\n",
      "Epoch 18/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - loss: 778545.4375\n",
      "Epoch 19/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 607us/step - loss: 581304.9375\n",
      "Epoch 20/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - loss: 441953.0312\n",
      "Epoch 21/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - loss: 211839.7656\n",
      "Epoch 22/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 653us/step - loss: 617795.5000\n",
      "Epoch 23/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 633us/step - loss: 319855.5000\n",
      "Epoch 24/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - loss: 220956.8281\n",
      "Epoch 25/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 611us/step - loss: 425124.4688\n",
      "Epoch 26/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - loss: 304706.8438\n",
      "Epoch 27/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 624us/step - loss: 232866.7500\n",
      "Epoch 28/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step - loss: 237232.9844\n",
      "Epoch 29/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627us/step - loss: 214344.5469\n",
      "Epoch 30/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 619us/step - loss: 220071.8594\n",
      "Epoch 31/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 657us/step - loss: 315518.2188\n",
      "Epoch 32/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 613us/step - loss: 196842.0469\n",
      "Epoch 33/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630us/step - loss: 217857.5625\n",
      "Epoch 34/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step - loss: 200855.0469\n",
      "Epoch 35/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - loss: 239001.0156\n",
      "Epoch 36/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627us/step - loss: 214688.7031\n",
      "Epoch 37/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628us/step - loss: 199535.3594\n",
      "Epoch 38/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 611us/step - loss: 192360.0781\n",
      "Epoch 39/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620us/step - loss: 209787.5938\n",
      "Epoch 40/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 660us/step - loss: 200546.5156\n",
      "Epoch 41/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 657us/step - loss: 188517.5469\n",
      "Epoch 42/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 608us/step - loss: 188157.0000\n",
      "Epoch 43/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - loss: 192089.8594\n",
      "Epoch 44/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - loss: 182190.1875\n",
      "Epoch 45/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 610us/step - loss: 184168.0625\n",
      "Epoch 46/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - loss: 196142.3438\n",
      "Epoch 47/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 760us/step - loss: 185836.0156\n",
      "Epoch 48/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 674us/step - loss: 176331.0156\n",
      "Epoch 49/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 640us/step - loss: 190249.8125\n",
      "Epoch 50/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 656us/step - loss: 179751.5000\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step\n",
      "RNN MSE: 166135.328125\n",
      "RNN R^2: 0.523608922958374\n"
     ]
    }
   ],
   "source": [
    "# RNN\n",
    "\n",
    "# Reshape data for RNN\n",
    "X_train_rnn = X_train.values.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test_rnn = X_test.values.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "# Initialize and train the model\n",
    "rnn = Sequential()\n",
    "rnn.add(SimpleRNN(50, activation='relu', input_shape=(1, X_train.shape[1])))\n",
    "rnn.add(Dense(1))\n",
    "rnn.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "X_train_rnn = X_train_rnn.astype('float32')\n",
    "y_train = y_train.astype('float32')\n",
    "X_test_rnn = X_test_rnn.astype('float32')\n",
    "y_test = y_test.astype('float32')\n",
    "rnn.fit(X_train_rnn, y_train, epochs=50, batch_size=32)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_rnn = rnn.predict(X_test_rnn)\n",
    "\n",
    "# Evaluate the model\n",
    "mse_rnn = mean_squared_error(y_test, y_pred_rnn)\n",
    "print(f'RNN MSE: {mse_rnn}')\n",
    "\n",
    "r2_rnn = r2_score(y_test, y_pred_rnn)\n",
    "print(f'RNN R^2: {r2_rnn}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR MSE: 367000.44033471425\n",
      "SVR R^2: -0.052369480880178676\n"
     ]
    }
   ],
   "source": [
    "# SVR\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# Initialize and train the model\n",
    "svr = SVR(kernel='rbf')\n",
    "svr.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_svr = svr.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse_svr = mean_squared_error(y_test, y_pred_svr)\n",
    "print(f'SVR MSE: {mse_svr}')\n",
    "r2_svr = r2_score(y_test, y_pred_svr)\n",
    "print(f'SVR R^2: {r2_svr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002641 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 992\n",
      "[LightGBM] [Info] Number of data points in the train set: 55104, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 532.107544\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "LightGBM MSE: 96883.21124118548\n",
      "LightGBM R^2: 0.7221885220984923\n"
     ]
    }
   ],
   "source": [
    "# LightGBM\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Initialize and train the model\n",
    "lgb_reg = lgb.LGBMRegressor(objective='regression', colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=100)\n",
    "lgb_reg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_lgb = lgb_reg.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse_lgb = mean_squared_error(y_test, y_pred_lgb)\n",
    "print(f'LightGBM MSE: {mse_lgb}')\n",
    "r2_lgb = r2_score(y_test, y_pred_lgb)\n",
    "print(f'LightGBM R^2: {r2_lgb}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest MSE: 34577.87175471353\n",
      "RNN MSE: 166135.328125\n",
      "SVR MSE: 367000.44033471425\n",
      "LightGBM MSE: 96883.21124118548\n"
     ]
    }
   ],
   "source": [
    "print(f'Random Forest MSE: {mse_rf}')\n",
    "print(f'RNN MSE: {mse_rnn}')\n",
    "print(f'SVR MSE: {mse_svr}')\n",
    "print(f'LightGBM MSE: {mse_lgb}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest R^2: 0.90084835719238\n",
      "RNN R^2: 0.523608922958374\n",
      "SVR R^2: -0.052369480880178676\n",
      "LightGBM R^2: 0.7221885220984923\n"
     ]
    }
   ],
   "source": [
    "print(f'Random Forest R^2: {r2_rf}')\n",
    "print(f'RNN R^2: {r2_rnn}')\n",
    "print(f'SVR R^2: {r2_svr}')\n",
    "print(f'LightGBM R^2: {r2_lgb}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Impressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_impression\n",
    "X_test = X_test_impression\n",
    "y_train = y_train_impression\n",
    "y_test = y_test_impression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest MSE: 203867.73175307052\n",
      "Random Forest R^2: 0.9726360831208117\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "print(f'Random Forest MSE: {mse_rf}')\n",
    "\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "print(f'Random Forest R^2: {r2_rf}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/santi/Desktop/Proyecto/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 744us/step - loss: 14669861.0000\n",
      "Epoch 2/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 590us/step - loss: 5567679.5000\n",
      "Epoch 3/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 644us/step - loss: 14054346.0000\n",
      "Epoch 4/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 646us/step - loss: 9241056.0000\n",
      "Epoch 5/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 602us/step - loss: 6495663.5000\n",
      "Epoch 6/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 604us/step - loss: 11633268.0000\n",
      "Epoch 7/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 595us/step - loss: 3947645.2500\n",
      "Epoch 8/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - loss: 8431471.0000\n",
      "Epoch 9/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 597us/step - loss: 6682678.0000\n",
      "Epoch 10/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 598us/step - loss: 9538562.0000\n",
      "Epoch 11/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 597us/step - loss: 5775943.0000\n",
      "Epoch 12/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step - loss: 3061385.7500\n",
      "Epoch 13/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647us/step - loss: 3842069.0000\n",
      "Epoch 14/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 665us/step - loss: 5927538.5000\n",
      "Epoch 15/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 613us/step - loss: 3176977.5000\n",
      "Epoch 16/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616us/step - loss: 1935392.8750\n",
      "Epoch 17/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 660us/step - loss: 15006535.0000\n",
      "Epoch 18/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 613us/step - loss: 11536614.0000\n",
      "Epoch 19/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 623us/step - loss: 1440838.5000\n",
      "Epoch 20/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 605us/step - loss: 2158530.2500\n",
      "Epoch 21/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 599us/step - loss: 1864290.5000\n",
      "Epoch 22/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step - loss: 3117547.7500\n",
      "Epoch 23/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 604us/step - loss: 1297069.6250\n",
      "Epoch 24/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 603us/step - loss: 7709353.0000\n",
      "Epoch 25/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 609us/step - loss: 4610468.0000\n",
      "Epoch 26/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639us/step - loss: 1390844.6250\n",
      "Epoch 27/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 611us/step - loss: 4356730.5000\n",
      "Epoch 28/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 610us/step - loss: 1029772.7500\n",
      "Epoch 29/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 598us/step - loss: 1327262.7500\n",
      "Epoch 30/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 604us/step - loss: 1790289.2500\n",
      "Epoch 31/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 600us/step - loss: 2997864.5000\n",
      "Epoch 32/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616us/step - loss: 2100359.7500\n",
      "Epoch 33/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 610us/step - loss: 1095743.3750\n",
      "Epoch 34/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639us/step - loss: 3232543.2500\n",
      "Epoch 35/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 602us/step - loss: 1205499.3750\n",
      "Epoch 36/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 607us/step - loss: 1616689.8750\n",
      "Epoch 37/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 607us/step - loss: 1864628.2500\n",
      "Epoch 38/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 596us/step - loss: 1738381.2500\n",
      "Epoch 39/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 601us/step - loss: 11728407.0000\n",
      "Epoch 40/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 623us/step - loss: 1126285.7500\n",
      "Epoch 41/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631us/step - loss: 1216238.1250\n",
      "Epoch 42/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 605us/step - loss: 1674307.7500\n",
      "Epoch 43/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 606us/step - loss: 1203653.3750\n",
      "Epoch 44/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 605us/step - loss: 1195488.2500\n",
      "Epoch 45/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 606us/step - loss: 1712139.5000\n",
      "Epoch 46/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 603us/step - loss: 1396473.8750\n",
      "Epoch 47/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 606us/step - loss: 1467206.0000\n",
      "Epoch 48/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 612us/step - loss: 1148612.8750\n",
      "Epoch 49/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647us/step - loss: 2507354.2500\n",
      "Epoch 50/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 624us/step - loss: 1228711.3750\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step\n",
      "RNN MSE: 1877349.625\n",
      "RNN R^2: 0.7480148077011108\n"
     ]
    }
   ],
   "source": [
    "# RNN\n",
    "\n",
    "# Reshape data for RNN\n",
    "X_train_rnn = X_train.values.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test_rnn = X_test.values.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "# Initialize and train the model\n",
    "rnn = Sequential()\n",
    "rnn.add(SimpleRNN(50, activation='relu', input_shape=(1, X_train.shape[1])))\n",
    "rnn.add(Dense(1))\n",
    "rnn.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "X_train_rnn = X_train_rnn.astype('float32')\n",
    "y_train = y_train.astype('float32')\n",
    "X_test_rnn = X_test_rnn.astype('float32')\n",
    "y_test = y_test.astype('float32')\n",
    "rnn.fit(X_train_rnn, y_train, epochs=50, batch_size=32)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_rnn = rnn.predict(X_test_rnn)\n",
    "\n",
    "# Evaluate the model\n",
    "mse_rnn = mean_squared_error(y_test, y_pred_rnn)\n",
    "print(f'RNN MSE: {mse_rnn}')\n",
    "\n",
    "r2_rnn = r2_score(y_test, y_pred_rnn)\n",
    "print(f'RNN R^2: {r2_rnn}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR MSE: 6870996.65314368\n",
      "SVR R^2: 0.07774820626573986\n"
     ]
    }
   ],
   "source": [
    "# SVR\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# Initialize and train the model\n",
    "svr = SVR(kernel='rbf')\n",
    "svr.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_svr = svr.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse_svr = mean_squared_error(y_test, y_pred_svr)\n",
    "print(f'SVR MSE: {mse_svr}')\n",
    "r2_svr = r2_score(y_test, y_pred_svr)\n",
    "print(f'SVR R^2: {r2_svr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005815 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 55104, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 1127.295351\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "LightGBM MSE: 908273.1647399026\n",
      "LightGBM R^2: 0.8780880565559851\n"
     ]
    }
   ],
   "source": [
    "# LightGBM\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Initialize and train the model\n",
    "lgb_reg = lgb.LGBMRegressor(objective='regression', colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=100)\n",
    "lgb_reg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_lgb = lgb_reg.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse_lgb = mean_squared_error(y_test, y_pred_lgb)\n",
    "print(f'LightGBM MSE: {mse_lgb}')\n",
    "r2_lgb = r2_score(y_test, y_pred_lgb)\n",
    "print(f'LightGBM R^2: {r2_lgb}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest MSE: 203867.73175307052\n",
      "RNN MSE: 1877349.625\n",
      "SVR MSE: 6870996.65314368\n",
      "LightGBM MSE: 908273.1647399026\n"
     ]
    }
   ],
   "source": [
    "print(f'Random Forest MSE: {mse_rf}')\n",
    "print(f'RNN MSE: {mse_rnn}')\n",
    "print(f'SVR MSE: {mse_svr}')\n",
    "print(f'LightGBM MSE: {mse_lgb}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest R^2: 0.9726360831208117\n",
      "RNN R^2: 0.7480148077011108\n",
      "SVR R^2: 0.07774820626573986\n",
      "LightGBM R^2: 0.8780880565559851\n"
     ]
    }
   ],
   "source": [
    "print(f'Random Forest R^2: {r2_rf}')\n",
    "print(f'RNN R^2: {r2_rnn}')\n",
    "print(f'SVR R^2: {r2_svr}')\n",
    "print(f'LightGBM R^2: {r2_lgb}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Clicks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_clicks\n",
    "X_test = X_test_clicks\n",
    "y_train = y_train_clicks\n",
    "y_test = y_test_clicks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest MSE: 8110.960041339211\n",
      "Random Forest R^2: 0.7795614006676789\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "print(f'Random Forest MSE: {mse_rf}')\n",
    "\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "print(f'Random Forest R^2: {r2_rf}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/santi/Desktop/Proyecto/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 552us/step - loss: 16108528.0000\n",
      "Epoch 2/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 576us/step - loss: 64480.9883\n",
      "Epoch 3/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 543us/step - loss: 13175037.0000\n",
      "Epoch 4/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 541us/step - loss: 1745407.3750\n",
      "Epoch 5/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 556us/step - loss: 6713369.0000\n",
      "Epoch 6/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 541us/step - loss: 1759061.7500\n",
      "Epoch 7/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 541us/step - loss: 18942582.0000\n",
      "Epoch 8/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 542us/step - loss: 33649.5000\n",
      "Epoch 9/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 541us/step - loss: 13506346.0000\n",
      "Epoch 10/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 542us/step - loss: 7578506.5000\n",
      "Epoch 11/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 542us/step - loss: 486257.9688\n",
      "Epoch 12/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 540us/step - loss: 6873879.0000\n",
      "Epoch 13/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 537us/step - loss: 78235.6172\n",
      "Epoch 14/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 572us/step - loss: 7827654.5000\n",
      "Epoch 15/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 541us/step - loss: 721241.4375\n",
      "Epoch 16/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 539us/step - loss: 1049061.2500\n",
      "Epoch 17/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 536us/step - loss: 4319991.5000\n",
      "Epoch 18/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 544us/step - loss: 58833.7148\n",
      "Epoch 19/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 539us/step - loss: 2551066.7500\n",
      "Epoch 20/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 538us/step - loss: 570908.9375\n",
      "Epoch 21/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 666us/step - loss: 824512.1875\n",
      "Epoch 22/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 661us/step - loss: 1086409.0000\n",
      "Epoch 23/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 675us/step - loss: 1024129.1875\n",
      "Epoch 24/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 704us/step - loss: 5698134.0000\n",
      "Epoch 25/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 688us/step - loss: 384946.1250\n",
      "Epoch 26/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 610us/step - loss: 1550347.3750\n",
      "Epoch 27/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 602us/step - loss: 83874.1094\n",
      "Epoch 28/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 649us/step - loss: 6213566.5000\n",
      "Epoch 29/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 707us/step - loss: 953955.0625\n",
      "Epoch 30/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 687us/step - loss: 929191.5000\n",
      "Epoch 31/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 600us/step - loss: 2797554.5000\n",
      "Epoch 32/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 606us/step - loss: 52463.0859\n",
      "Epoch 33/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 606us/step - loss: 414024.3750\n",
      "Epoch 34/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - loss: 1049289.7500\n",
      "Epoch 35/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 604us/step - loss: 38473.8242\n",
      "Epoch 36/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 607us/step - loss: 185639.7188\n",
      "Epoch 37/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 633us/step - loss: 48525.7617\n",
      "Epoch 38/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 600us/step - loss: 495929.0938\n",
      "Epoch 39/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 610us/step - loss: 48543.0430\n",
      "Epoch 40/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 598us/step - loss: 808833.4375\n",
      "Epoch 41/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 611us/step - loss: 4215199.0000\n",
      "Epoch 42/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 598us/step - loss: 66327.6797\n",
      "Epoch 43/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 599us/step - loss: 2174652.7500\n",
      "Epoch 44/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 608us/step - loss: 649753.3125\n",
      "Epoch 45/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 648us/step - loss: 397148.1250\n",
      "Epoch 46/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 591us/step - loss: 258046.9375\n",
      "Epoch 47/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 611us/step - loss: 234477.5938\n",
      "Epoch 48/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 605us/step - loss: 113358.4922\n",
      "Epoch 49/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 607us/step - loss: 478851.5000\n",
      "Epoch 50/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 608us/step - loss: 104286.0938\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step\n",
      "RNN MSE: 117672.796875\n",
      "RNN R^2: -2.1980955600738525\n"
     ]
    }
   ],
   "source": [
    "# RNN\n",
    "\n",
    "# Reshape data for RNN\n",
    "X_train_rnn = X_train.values.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test_rnn = X_test.values.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "# Initialize and train the model\n",
    "rnn = Sequential()\n",
    "rnn.add(SimpleRNN(50, activation='relu', input_shape=(1, X_train.shape[1])))\n",
    "rnn.add(Dense(1))\n",
    "rnn.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "X_train_rnn = X_train_rnn.astype('float32')\n",
    "y_train = y_train.astype('float32')\n",
    "X_test_rnn = X_test_rnn.astype('float32')\n",
    "y_test = y_test.astype('float32')\n",
    "rnn.fit(X_train_rnn, y_train, epochs=50, batch_size=32)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_rnn = rnn.predict(X_test_rnn)\n",
    "\n",
    "# Evaluate the model\n",
    "mse_rnn = mean_squared_error(y_test, y_pred_rnn)\n",
    "print(f'RNN MSE: {mse_rnn}')\n",
    "\n",
    "r2_rnn = r2_score(y_test, y_pred_rnn)\n",
    "print(f'RNN R^2: {r2_rnn}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR MSE: 35318.09438202734\n",
      "SVR R^2: 0.0401295016890062\n"
     ]
    }
   ],
   "source": [
    "# SVR\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# Initialize and train the model\n",
    "svr = SVR(kernel='rbf')\n",
    "svr.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_svr = svr.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse_svr = mean_squared_error(y_test, y_pred_svr)\n",
    "print(f'SVR MSE: {mse_svr}')\n",
    "r2_svr = r2_score(y_test, y_pred_svr)\n",
    "print(f'SVR R^2: {r2_svr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001880 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 55104, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 33.488912\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "LightGBM MSE: 16571.654443392305\n",
      "LightGBM R^2: 0.5496177671321041\n"
     ]
    }
   ],
   "source": [
    "# LightGBM\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Initialize and train the model\n",
    "lgb_reg = lgb.LGBMRegressor(objective='regression', colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=100)\n",
    "lgb_reg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_lgb = lgb_reg.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse_lgb = mean_squared_error(y_test, y_pred_lgb)\n",
    "print(f'LightGBM MSE: {mse_lgb}')\n",
    "r2_lgb = r2_score(y_test, y_pred_lgb)\n",
    "print(f'LightGBM R^2: {r2_lgb}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest MSE: 8110.960041339211\n",
      "RNN MSE: 117672.796875\n",
      "SVR MSE: 35318.09438202734\n",
      "LightGBM MSE: 16571.654443392305\n"
     ]
    }
   ],
   "source": [
    "print(f'Random Forest MSE: {mse_rf}')\n",
    "print(f'RNN MSE: {mse_rnn}')\n",
    "print(f'SVR MSE: {mse_svr}')\n",
    "print(f'LightGBM MSE: {mse_lgb}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest R^2: 0.7795614006676789\n",
      "RNN R^2: -2.1980955600738525\n",
      "SVR R^2: 0.0401295016890062\n",
      "LightGBM R^2: 0.5496177671321041\n"
     ]
    }
   ],
   "source": [
    "print(f'Random Forest R^2: {r2_rf}')\n",
    "print(f'RNN R^2: {r2_rnn}')\n",
    "print(f'SVR R^2: {r2_svr}')\n",
    "print(f'LightGBM R^2: {r2_lgb}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Media Cost ($)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_media_cost_usd\n",
    "X_test = X_test_media_cost_usd\n",
    "y_train = y_train_media_cost_usd\n",
    "y_test = y_test_media_cost_usd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest MSE: 17.578946335901556\n",
      "Random Forest R^2: 0.9794667467638998\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "print(f'Random Forest MSE: {mse_rf}')\n",
    "\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "print(f'Random Forest R^2: {r2_rf}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/santi/Desktop/Proyecto/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 552us/step - loss: 90790288.0000\n",
      "Epoch 2/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 552us/step - loss: 3178282.2500\n",
      "Epoch 3/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 544us/step - loss: 1919058.5000\n",
      "Epoch 4/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 547us/step - loss: 10968.8525\n",
      "Epoch 5/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 545us/step - loss: 13583471.0000\n",
      "Epoch 6/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 739us/step - loss: 13409425.0000\n",
      "Epoch 7/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 559us/step - loss: 413207.7812\n",
      "Epoch 8/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 651us/step - loss: 2194928.0000\n",
      "Epoch 9/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 610us/step - loss: 761225.0000\n",
      "Epoch 10/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 602us/step - loss: 67507.4062\n",
      "Epoch 11/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 683us/step - loss: 7139.1880\n",
      "Epoch 12/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 713us/step - loss: 8846198.0000\n",
      "Epoch 13/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 617us/step - loss: 3001914.0000\n",
      "Epoch 14/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 634us/step - loss: 3536.9666\n",
      "Epoch 15/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 614us/step - loss: 7307716.0000\n",
      "Epoch 16/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 608us/step - loss: 364470.2812\n",
      "Epoch 17/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 645us/step - loss: 484929.4375\n",
      "Epoch 18/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 614us/step - loss: 4603.4448\n",
      "Epoch 19/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 608us/step - loss: 1130241.1250\n",
      "Epoch 20/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 599us/step - loss: 10908.8916\n",
      "Epoch 21/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 609us/step - loss: 6009031.0000\n",
      "Epoch 22/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631us/step - loss: 114580.1250\n",
      "Epoch 23/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 602us/step - loss: 36009.8242\n",
      "Epoch 24/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 607us/step - loss: 728617.8750\n",
      "Epoch 25/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 603us/step - loss: 13125.3867\n",
      "Epoch 26/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639us/step - loss: 399680.0938\n",
      "Epoch 27/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 602us/step - loss: 157499.3750\n",
      "Epoch 28/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 610us/step - loss: 466564.0000\n",
      "Epoch 29/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 636us/step - loss: 5707.1782\n",
      "Epoch 30/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 607us/step - loss: 532297.7500\n",
      "Epoch 31/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 605us/step - loss: 199628.2344\n",
      "Epoch 32/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 583us/step - loss: 11953.4590\n",
      "Epoch 33/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 605us/step - loss: 45288.6055\n",
      "Epoch 34/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 610us/step - loss: 47678.4531\n",
      "Epoch 35/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 643us/step - loss: 132228.5625\n",
      "Epoch 36/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 602us/step - loss: 664.0389\n",
      "Epoch 37/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620us/step - loss: 648945.1875\n",
      "Epoch 38/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 646us/step - loss: 120587.1797\n",
      "Epoch 39/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 634us/step - loss: 29938.0430\n",
      "Epoch 40/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 663us/step - loss: 133315.6719\n",
      "Epoch 41/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 619us/step - loss: 166712.6094\n",
      "Epoch 42/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 633us/step - loss: 198158.6250\n",
      "Epoch 43/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 611us/step - loss: 245287.8906\n",
      "Epoch 44/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step - loss: 59060.9609\n",
      "Epoch 45/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 643us/step - loss: 15802.3828\n",
      "Epoch 46/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 606us/step - loss: 23156.6191\n",
      "Epoch 47/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 623us/step - loss: 20505.5801\n",
      "Epoch 48/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 623us/step - loss: 414.8444\n",
      "Epoch 49/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615us/step - loss: 82593.2500\n",
      "Epoch 50/50\n",
      "\u001b[1m1722/1722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 659us/step - loss: 118788.3438\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step\n",
      "RNN MSE: 163.70155334472656\n",
      "RNN R^2: 0.8087868690490723\n"
     ]
    }
   ],
   "source": [
    "# RNN\n",
    "\n",
    "# Reshape data for RNN\n",
    "X_train_rnn = X_train.values.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test_rnn = X_test.values.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "# Initialize and train the model\n",
    "rnn = Sequential()\n",
    "rnn.add(SimpleRNN(50, activation='relu', input_shape=(1, X_train.shape[1])))\n",
    "rnn.add(Dense(1))\n",
    "rnn.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "X_train_rnn = X_train_rnn.astype('float32')\n",
    "y_train = y_train.astype('float32')\n",
    "X_test_rnn = X_test_rnn.astype('float32')\n",
    "y_test = y_test.astype('float32')\n",
    "rnn.fit(X_train_rnn, y_train, epochs=50, batch_size=32)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_rnn = rnn.predict(X_test_rnn)\n",
    "\n",
    "# Evaluate the model\n",
    "mse_rnn = mean_squared_error(y_test, y_pred_rnn)\n",
    "print(f'RNN MSE: {mse_rnn}')\n",
    "\n",
    "r2_rnn = r2_score(y_test, y_pred_rnn)\n",
    "print(f'RNN R^2: {r2_rnn}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR MSE: 770.1692109580182\n",
      "SVR R^2: 0.10039663394230902\n"
     ]
    }
   ],
   "source": [
    "# SVR\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# Initialize and train the model\n",
    "svr = SVR(kernel='rbf')\n",
    "svr.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_svr = svr.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse_svr = mean_squared_error(y_test, y_pred_svr)\n",
    "print(f'SVR MSE: {mse_svr}')\n",
    "r2_svr = r2_score(y_test, y_pred_svr)\n",
    "print(f'SVR R^2: {r2_svr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002680 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 55104, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 8.825605\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "LightGBM MSE: 137.88229545261987\n",
      "LightGBM R^2: 0.8389452923538133\n"
     ]
    }
   ],
   "source": [
    "# LightGBM\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Initialize and train the model\n",
    "lgb_reg = lgb.LGBMRegressor(objective='regression', colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=100)\n",
    "lgb_reg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_lgb = lgb_reg.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse_lgb = mean_squared_error(y_test, y_pred_lgb)\n",
    "print(f'LightGBM MSE: {mse_lgb}')\n",
    "r2_lgb = r2_score(y_test, y_pred_lgb)\n",
    "print(f'LightGBM R^2: {r2_lgb}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest MSE: 17.578946335901556\n",
      "RNN MSE: 163.70155334472656\n",
      "SVR MSE: 770.1692109580182\n",
      "LightGBM MSE: 137.88229545261987\n"
     ]
    }
   ],
   "source": [
    "print(f'Random Forest MSE: {mse_rf}')\n",
    "print(f'RNN MSE: {mse_rnn}')\n",
    "print(f'SVR MSE: {mse_svr}')\n",
    "print(f'LightGBM MSE: {mse_lgb}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest R^2: 0.9794667467638998\n",
      "RNN R^2: 0.8087868690490723\n",
      "SVR R^2: 0.10039663394230902\n",
      "LightGBM R^2: 0.8389452923538133\n"
     ]
    }
   ],
   "source": [
    "print(f'Random Forest R^2: {r2_rf}')\n",
    "print(f'RNN R^2: {r2_rnn}')\n",
    "print(f'SVR R^2: {r2_svr}')\n",
    "print(f'LightGBM R^2: {r2_lgb}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
